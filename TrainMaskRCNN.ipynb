{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGWTPWBIx370"
      },
      "source": [
        "## **1. Installation**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia28v1VeyPnS",
        "outputId": "850832e8-4ecf-4020-96eb-8e9bad07bd90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-23 06:25:35--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.20.126\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.20.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 430460776 (411M) [application/x-deb]\n",
            "Saving to: ‘libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb’\n",
            "\n",
            "libcudnn8_8.1.0.77- 100%[===================>] 410.52M   231MB/s    in 1.8s    \n",
            "\n",
            "2023-04-23 06:25:37 (231 MB/s) - ‘libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb’ saved [430460776/430460776]\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.7.0.84-1+cuda11.8 to 8.1.0.77-1+cuda11.2\n",
            "(Reading database ... 122352 files and directories currently installed.)\n",
            "Preparing to unpack libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.7.0.84-1+cuda11.8) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n",
            "lrwxrwxrwx 1 root root     17 Jan 25  2021 /usr/lib/x86_64-linux-gnu/libcudnn.so.8 -> libcudnn.so.8.1.0\n",
            "-rw-r--r-- 1 root root 158264 Jan 25  2021 /usr/lib/x86_64-linux-gnu/libcudnn.so.8.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.40.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py~=3.1.0\n",
            "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.20.3)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six~=1.15.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (2.12.2)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (67.6.1)\n",
            "Collecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.4.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (6.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.2)\n",
            "Building wheels for collected packages: termcolor, wrapt\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4845 sha256=129d8ece167a205e0fc4ffbc7de6bead489d17a6561cc23bdab70c6e844ff5b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp39-cp39-linux_x86_64.whl size=75947 sha256=c2ae1b26c9928e6a6e6b3675fcbc80127b5b9a3024a66be361b780e48abf0799\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n",
            "Successfully built termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, keras-nightly, flatbuffers, tensorboard-data-server, six, numpy, keras-preprocessing, h5py, grpcio, absl-py, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.2.0\n",
            "    Uninstalling termcolor-2.2.0:\n",
            "      Successfully uninstalled termcolor-2.2.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.8.0\n",
            "    Uninstalling h5py-3.8.0:\n",
            "      Successfully uninstalled h5py-3.8.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.53.0\n",
            "    Uninstalling grpcio-1.53.0:\n",
            "      Successfully uninstalled grpcio-1.53.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "sqlalchemy 2.0.9 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "pydantic 1.10.7 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "polars 0.17.3 requires typing_extensions>=4.0.1; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "pandas 1.5.3 requires numpy>=1.20.3; python_version < \"3.10\", but you have numpy 1.19.5 which is incompatible.\n",
            "optax 0.1.4 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "ml-dtypes 0.1.0 requires numpy>1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "matplotlib 3.7.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "librosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.19.5 which is incompatible.\n",
            "librosa 0.10.0.post2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.4.7+cuda11.cudnn86 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.4.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.34.1 which is incompatible.\n",
            "google-cloud-bigquery 3.9.0 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n",
            "flax 0.6.8 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "chex 0.1.7 requires typing-extensions>=4.2.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "bokeh 2.4.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "astropy 5.2.2 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "arviz 0.15.1 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\n",
            "arviz 0.15.1 requires typing-extensions>=4.1.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-0.15.0 flatbuffers-1.12 google-auth-oauthlib-0.4.6 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 numpy-1.19.5 six-1.15.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        }
      ],
      "source": [
        "# Update CUDA for TF 2.5\n",
        "\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\n",
        "!sudo dpkg -i libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\n",
        "\n",
        "# Check if package has been installed\n",
        "\n",
        "!sudo ls -l /usr/lib/x86_64-linux-gnu/libcudnn.so.*\n",
        "\n",
        "# Upgrade Tensorflow\n",
        "!pip install --upgrade tensorflow==2.5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulXTP0uuBdOl"
      },
      "source": [
        "Install Mask R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md87Hxgtn6zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54cf909c-3fe8-4f5b-d61a-ddf256d11d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-23 06:51:56--  https://psfiles.link/project/mask_rcnn_colab/mrcnn_demo_PIBVGJTEFX.zip\n",
            "Resolving psfiles.link (psfiles.link)... 34.90.26.83\n",
            "Connecting to psfiles.link (psfiles.link)|34.90.26.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59799 (58K) [application/zip]\n",
            "Saving to: ‘mrcnn_demo_PIBVGJTEFX.zip’\n",
            "\n",
            "mrcnn_demo_PIBVGJTE 100%[===================>]  58.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-23 06:51:57 (224 MB/s) - ‘mrcnn_demo_PIBVGJTEFX.zip’ saved [59799/59799]\n",
            "\n",
            "Archive:  mrcnn_demo_PIBVGJTEFX.zip\n",
            "   creating: maskrcnn_colab/\n",
            "   creating: maskrcnn_colab/mrcnn_demo/\n",
            "  inflating: maskrcnn_colab/mrcnn_demo/config.py  \n",
            "  inflating: maskrcnn_colab/mrcnn_demo/model.py  \n",
            "  inflating: maskrcnn_colab/mrcnn_demo/m_rcnn.py  \n",
            "  inflating: maskrcnn_colab/mrcnn_demo/parallel_model.py  \n",
            "  inflating: maskrcnn_colab/mrcnn_demo/utils.py  \n",
            "  inflating: maskrcnn_colab/mrcnn_demo/visualize.py  \n",
            "VERS 0.5 - updated 11/03/2023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/maskrcnn_colab/mrcnn_demo/model.py:2378: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if os.name is 'nt':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pretrained model to /content/maskrcnn_colab/mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n"
          ]
        }
      ],
      "source": [
        "!wget https://psfiles.link/project/mask_rcnn_colab/mrcnn_demo_PIBVGJTEFX.zip\n",
        "!unzip mrcnn_demo_PIBVGJTEFX.zip\n",
        "import sys\n",
        "sys.path.append(\"/content/maskrcnn_colab/mrcnn_demo\")\n",
        "from m_rcnn import *\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvM9sdw3Vou_",
        "outputId": "9a5c53d3-04bb-4cf0-b178-66f8e49b053c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr 23 06:52:08 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omb3Yl6ABqiJ"
      },
      "source": [
        "## **2. Image Dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlNYqGhvqb_p",
        "outputId": "ff3c7503-35ef-499b-c215-570cf0218654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted: 43 images\n"
          ]
        }
      ],
      "source": [
        "# Extract Images\n",
        "images_path = \"dataset.zip\"\n",
        "annotations_path = \"annotations.json\"\n",
        "\n",
        "extract_images(os.path.join(\"/content/\",images_path), \"/content/dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnW8ETPKzqFT",
        "outputId": "48235a14-2fe9-4e18-95a2-3d43cd0255a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotation json path:  /content/annotations.json\n",
            "Annotation json path:  /content/annotations.json\n",
            "Train: 39\n",
            "Validation: 4\n",
            "Classes: 1\n"
          ]
        }
      ],
      "source": [
        "dataset_train = load_image_dataset(os.path.join(\"/content/\", annotations_path), \"/content/dataset\", \"train\")\n",
        "dataset_val = load_image_dataset(os.path.join(\"/content/\", annotations_path), \"/content/dataset\", \"val\")\n",
        "class_number = dataset_train.count_classes()\n",
        "print('Train: %d' % len(dataset_train.image_ids))\n",
        "print('Validation: %d' % len(dataset_val.image_ids))\n",
        "print(\"Classes: {}\".format(class_number))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umeaqvVeBqiL"
      },
      "outputs": [],
      "source": [
        "# Load image samples\n",
        "display_image_samples(dataset_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9k3Wm0_BqiN"
      },
      "source": [
        "##**3. Training**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axkqWaZ7z_4p",
        "outputId": "5d787d59-cca2-4f82-9ec2-789d2509fc1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/maskrcnn_colab/mask_rcnn_coco.h5\n"
          ]
        }
      ],
      "source": [
        "# Load Configuration\n",
        "config = CustomConfig(class_number)\n",
        "# config.display()\n",
        "model = load_training_model(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyzLXzF5BqiN",
        "outputId": "d12d9f66-7f18-4403-bdcf-cea085d8ec62",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/maskrcnn_colab/logs/object20230423T0658/mask_rcnn_object_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "rpn_model              (Functional)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 1064s 2s/step - batch: 249.5000 - size: 4.0000 - loss: 0.4107 - val_loss: 0.2503\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 945s 2s/step - batch: 249.5000 - size: 4.0000 - loss: 0.1839 - val_loss: 0.1189\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 981s 2s/step - batch: 249.5000 - size: 4.0000 - loss: 0.1410 - val_loss: 0.0798\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 994s 2s/step - batch: 249.5000 - size: 4.0000 - loss: 0.1005 - val_loss: 0.1520\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 998s 2s/step - batch: 249.5000 - size: 4.0000 - loss: 0.0899 - val_loss: 0.0630\n"
          ]
        }
      ],
      "source": [
        "# Start Training\n",
        "# This operation might take a long time.\n",
        "train_head(model, dataset_train, dataset_train, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6npLKIL3BqiO"
      },
      "source": [
        "### 4. Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUwXQ6h7BqiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80a3f9c-c577-4e90-b72a-29efa4cd3b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from  /content/maskrcnn_colab/logs/object20230423T0658/mask_rcnn_object_0005.h5\n",
            "Re-starting from epoch 5\n"
          ]
        }
      ],
      "source": [
        "# Load Test Model\n",
        "# The latest trained model will be loaded\n",
        "test_model, inference_config = load_test_model(class_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8uzE5U3BqiP"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "test_random_image(test_model, dataset_val, inference_config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rGWTPWBIx370",
        "Omb3Yl6ABqiJ",
        "Z9k3Wm0_BqiN",
        "6npLKIL3BqiO"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}